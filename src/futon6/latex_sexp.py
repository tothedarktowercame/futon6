"""LaTeX â†’ s-expression parser for mathematical expressions.

Stage 8 of the futon6 pipeline: parse every $...$ LaTeX expression into
a typed s-expression tree. Each expression becomes a surface for wiring.

    >>> parse(r"\\Gamma=(V,E,s,t)")
    '(= Î“ (tuple V E s t))'
    >>> parse(r"s(X(e))=X(s(e))")
    '(= (s (X e)) (X (s e)))'
    >>> parse(r"e : v \\to w")
    '(: e (â†’ v w))'
"""

from __future__ import annotations

import re
from dataclasses import dataclass
from typing import Union

# ---------------------------------------------------------------------------
# S-expression AST
# ---------------------------------------------------------------------------

@dataclass
class Atom:
    value: str
    def __str__(self) -> str:
        return self.value

@dataclass
class App:
    """Function application or operator: (op arg1 arg2 ...)"""
    op: str
    args: list[SExp]
    def __str__(self) -> str:
        if not self.args:
            return self.op
        parts = [self.op] + [str(a) for a in self.args]
        return '(' + ' '.join(parts) + ')'

SExp = Union[Atom, App]


# ---------------------------------------------------------------------------
# Greek / symbol mapping
# ---------------------------------------------------------------------------

GREEK = {
    'alpha': 'Î±', 'beta': 'Î²', 'gamma': 'Î³', 'delta': 'Î´', 'epsilon': 'Îµ',
    'zeta': 'Î¶', 'eta': 'Î·', 'theta': 'Î¸', 'iota': 'Î¹', 'kappa': 'Îº',
    'lambda': 'Î»', 'mu': 'Î¼', 'nu': 'Î½', 'xi': 'Î¾', 'pi': 'Ï€',
    'rho': 'Ï', 'sigma': 'Ïƒ', 'tau': 'Ï„', 'upsilon': 'Ï…', 'phi': 'Ï†',
    'chi': 'Ï‡', 'psi': 'Ïˆ', 'omega': 'Ï‰',
    'Gamma': 'Î“', 'Delta': 'Î”', 'Theta': 'Î˜', 'Lambda': 'Î›',
    'Xi': 'Î', 'Pi': 'Î ', 'Sigma': 'Î£', 'Upsilon': 'Î¥',
    'Phi': 'Î¦', 'Psi': 'Î¨', 'Omega': 'Î©',
}

OPERATORS = {
    'in': 'âˆˆ', 'notin': 'âˆ‰', 'subset': 'âŠ‚', 'subseteq': 'âŠ†',
    'supset': 'âŠƒ', 'supseteq': 'âŠ‡', 'cup': 'âˆª', 'cap': 'âˆ©',
    'circ': 'âˆ˜', 'cdot': 'Â·', 'times': 'Ã—', 'otimes': 'âŠ—',
    'oplus': 'âŠ•', 'to': 'â†’', 'rightarrow': 'â†’', 'leftarrow': 'â†',
    'Rightarrow': 'â‡’', 'Leftarrow': 'â‡', 'leftrightarrow': 'â†”',
    'mapsto': 'â†¦', 'hookrightarrow': 'â†ª',
    'forall': 'âˆ€', 'exists': 'âˆƒ', 'neg': 'Â¬',
    'land': 'âˆ§', 'lor': 'âˆ¨', 'implies': 'âŸ¹',
    'leq': 'â‰¤', 'geq': 'â‰¥', 'neq': 'â‰ ', 'equiv': 'â‰¡',
    'approx': 'â‰ˆ', 'sim': 'âˆ¼', 'cong': 'â‰…', 'simeq': 'â‰ƒ',
    'pm': 'Â±', 'mp': 'âˆ“', 'infty': 'âˆ', 'emptyset': 'âˆ…',
    'rightrightarrows': 'â‡‰', 'downarrow': 'â†“', 'uparrow': 'â†‘',
    'bullet': 'â€¢',
}

# Binary operators by precedence (low to high)
BINOP_PRECEDENCE = {
    ':=': 1, '=': 2, 'â‰ ': 2, 'â‰¡': 2, 'â‰…': 2, 'â‰ƒ': 2, 'â‰ˆ': 2,
    ':': 3,
    'âˆˆ': 4, 'âˆ‰': 4, 'âŠ‚': 4, 'âŠ†': 4, 'âŠƒ': 4, 'âŠ‡': 4,
    'â†’': 5, 'â†': 5, 'â†”': 5, 'â‡’': 5, 'â‡': 5, 'â†¦': 5, 'â†ª': 5,
    '+': 6, '-': 6, 'Â±': 6, 'âˆª': 6, 'âˆ¨': 6,
    'âˆ˜': 7, 'Â·': 7, 'Ã—': 7, 'âŠ—': 7, 'âŠ•': 7, 'âˆ§': 7,
}


# ---------------------------------------------------------------------------
# Tokenizer
# ---------------------------------------------------------------------------

@dataclass
class Token:
    kind: str   # 'ident', 'number', 'op', 'lparen', 'rparen', 'lbrace',
                # 'rbrace', 'comma', 'sub', 'sup', 'prime', 'command', 'eof'
    value: str

_TOKEN_RE = re.compile(r"""
    (?P<newline>\\\\)               |  # \\ (LaTeX newline / array row sep)
    (?P<command>\\[a-zA-Z]+)       |  # \command
    (?P<number>[0-9]+(?:\.[0-9]+)?) |  # numbers
    (?P<defeq>:=)                   |  # := (before : alone)
    (?P<op>[=:<>+\-])               |  # single-char operators
    (?P<lparen>[(])                  |
    (?P<rparen>[)])                  |
    (?P<lbrace>[{])                  |
    (?P<rbrace>[}])                  |
    (?P<lbracket>\[)                 |
    (?P<rbracket>\])                 |
    (?P<comma>,)                     |
    (?P<sub>_)                       |
    (?P<sup>\^)                      |
    (?P<prime>')                     |
    (?P<ident>[a-zA-Z])              |  # single letter identifiers
    (?P<ws>\s+)                      |  # whitespace (skip)
    (?P<amp>&)                       |  # array separator (skip)
    (?P<other>.)                        # anything else
""", re.VERBOSE)


def tokenize(latex: str) -> list[Token]:
    tokens = []
    for m in _TOKEN_RE.finditer(latex):
        kind = m.lastgroup
        val = m.group()
        if kind in ('ws', 'amp'):
            continue
        if kind == 'newline':
            tokens.append(Token('newline', '\\\\'))
            continue
        if kind == 'command':
            cmd = val[1:]  # strip backslash
            if cmd in GREEK:
                tokens.append(Token('ident', GREEK[cmd]))
            elif cmd in OPERATORS:
                tokens.append(Token('op', OPERATORS[cmd]))
            elif cmd in ('mathcal', 'mathsf', 'mathrm', 'mathbb',
                         'mathbf', 'mathit', 'text', 'textbf', 'textit'):
                tokens.append(Token('command', cmd))
            elif cmd == 'frac':
                tokens.append(Token('command', 'frac'))
            elif cmd in ('left', 'right', 'big', 'Big', 'bigg', 'Bigg'):
                continue  # sizing â€” skip
            elif cmd in ('quad', 'qquad', 'hspace', 'hfill', ',', ';'):
                continue  # spacing â€” skip
            elif cmd == 'bar':
                tokens.append(Token('command', 'bar'))
            elif cmd in ('hat', 'tilde', 'vec', 'dot', 'ddot', 'overline', 'underline'):
                tokens.append(Token('command', cmd))
            elif cmd == 'begin' or cmd == 'end':
                tokens.append(Token('command', cmd))
            else:
                # Unknown command â€” treat as identifier
                tokens.append(Token('ident', cmd))
        elif kind == 'defeq':
            tokens.append(Token('op', ':='))
        elif kind == 'op':
            if val == ':':
                tokens.append(Token('op', ':'))
            elif val == '=':
                tokens.append(Token('op', '='))
            elif val == '<':
                tokens.append(Token('op', '<'))
            elif val == '>':
                tokens.append(Token('op', '>'))
            elif val == '+':
                tokens.append(Token('op', '+'))
            elif val == '-':
                tokens.append(Token('op', '-'))
        elif kind == 'other':
            if val == '\\':
                continue  # stray backslash
            # skip unknown chars
            continue
        else:
            tokens.append(Token(kind, val))
    tokens.append(Token('eof', ''))
    return tokens


# ---------------------------------------------------------------------------
# Parser (recursive descent with precedence climbing)
# ---------------------------------------------------------------------------

class Parser:
    def __init__(self, tokens: list[Token]):
        self.tokens = tokens
        self.pos = 0

    def peek(self) -> Token:
        return self.tokens[self.pos]

    def advance(self) -> Token:
        t = self.tokens[self.pos]
        self.pos += 1
        return t

    def expect(self, kind: str) -> Token:
        t = self.advance()
        if t.kind != kind:
            raise ParseError(f"expected {kind}, got {t.kind} ({t.value!r})")
        return t

    def at(self, kind: str, value: str | None = None) -> bool:
        t = self.peek()
        if t.kind != kind:
            return False
        if value is not None and t.value != value:
            return False
        return True

    def parse_expr(self, min_prec: int = 0) -> SExp:
        """Precedence climbing for binary operators, with comma as tuple."""
        left = self.parse_unary()

        while True:
            t = self.peek()

            # Comma at top level â†’ tuple
            if t.kind == 'comma' and min_prec == 0:
                items = [left]
                while self.at('comma'):
                    self.advance()
                    items.append(self.parse_expr(1))
                left = App('tuple', items) if len(items) > 1 else items[0]
                break

            if t.kind != 'op' or t.value not in BINOP_PRECEDENCE:
                break
            prec = BINOP_PRECEDENCE[t.value]
            if prec < min_prec:
                break
            op = self.advance().value
            right = self.parse_expr(prec + 1)
            left = App(op, [left, right])

        return left

    def parse_unary(self) -> SExp:
        """Parse a unary expression (atom, possibly with subscript/superscript/application)."""
        t = self.peek()

        # Quantifiers: âˆ€, âˆƒ
        if t.kind == 'op' and t.value in ('âˆ€', 'âˆƒ'):
            self.advance()
            body = self.parse_expr(0)
            return App(t.value, [body])

        # Negation
        if t.kind == 'op' and t.value == 'Â¬':
            self.advance()
            body = self.parse_unary()
            return App('Â¬', [body])

        base = self.parse_atom()

        # Post-modifiers: subscript, superscript, prime, application
        while True:
            t = self.peek()
            if t.kind == 'sub':
                self.advance()
                sub = self.parse_atom()
                base = App('sub', [base, sub])
            elif t.kind == 'sup':
                self.advance()
                sup = self.parse_atom()
                base = App('sup', [base, sup])
            elif t.kind == 'prime':
                self.advance()
                base = App('prime', [base])
            elif t.kind == 'lparen':
                # Function application: f(x) or f(x,y,...)
                args = self.parse_paren_args()
                if len(args) == 1 and isinstance(args[0], Atom) and args[0].value == '-':
                    # f(-) â†’ placeholder notation
                    base = App(str(base), [Atom('â–¡')])
                else:
                    base = App(str(base), args)
            else:
                break

        return base

    def parse_atom(self) -> SExp:
        t = self.peek()

        if t.kind == 'ident':
            self.advance()
            return Atom(t.value)

        if t.kind == 'number':
            self.advance()
            return Atom(t.value)

        if t.kind == 'op' and t.value in ('â€¢', 'âˆ', 'âˆ…', '-'):
            self.advance()
            return Atom(t.value)

        if t.kind == 'command':
            return self.parse_command()

        if t.kind == 'lparen':
            return self.parse_paren()

        if t.kind == 'lbrace':
            return self.parse_brace_group()

        if t.kind == 'lbracket':
            self.advance()
            inner = self.parse_expr(0)
            if self.at('rbracket'):
                self.advance()
            return inner

        # Fallback: skip and return placeholder
        self.advance()
        return Atom('?')

    def parse_command(self) -> SExp:
        t = self.advance()
        cmd = t.value

        if cmd in ('mathcal', 'mathsf', 'mathrm', 'mathbb', 'mathbf',
                    'mathit', 'text', 'textbf', 'textit'):
            # \mathcal{C} â†’ the decorated name
            content = self.parse_brace_content()
            # For single letters in mathcal/mathbb, use unicode if possible
            if cmd == 'mathcal' and len(content) == 1:
                MATHCAL = {'A': 'ğ’œ', 'B': 'â„¬', 'C': 'ğ’', 'D': 'ğ’Ÿ', 'E': 'â„°',
                           'F': 'â„±', 'G': 'ğ’¢', 'H': 'â„‹', 'I': 'â„', 'J': 'ğ’¥',
                           'K': 'ğ’¦', 'L': 'â„’', 'M': 'â„³', 'N': 'ğ’©', 'O': 'ğ’ª',
                           'P': 'ğ’«', 'Q': 'ğ’¬', 'R': 'â„›', 'S': 'ğ’®', 'T': 'ğ’¯',
                           'U': 'ğ’°', 'V': 'ğ’±', 'W': 'ğ’²', 'X': 'ğ’³', 'Y': 'ğ’´',
                           'Z': 'ğ’µ'}
                return Atom(MATHCAL.get(content, content))
            elif cmd == 'mathbb' and len(content) == 1:
                MATHBB = {'N': 'â„•', 'Z': 'â„¤', 'Q': 'â„š', 'R': 'â„', 'C': 'â„‚',
                           'P': 'â„™', 'F': 'ğ”½'}
                return Atom(MATHBB.get(content, content))
            else:
                return Atom(content)

        if cmd == 'frac':
            num = self.parse_brace_group()
            den = self.parse_brace_group()
            return App('/', [num, den])

        if cmd in ('bar', 'overline'):
            arg = self.parse_atom()
            return App('bar', [arg])

        if cmd in ('hat', 'tilde', 'vec', 'dot', 'ddot', 'underline'):
            arg = self.parse_atom()
            return App(cmd, [arg])

        if cmd == 'begin':
            return self.parse_environment()

        if cmd == 'end':
            # consume {envname} and return placeholder
            self.parse_brace_content()
            return Atom('')

        return Atom(cmd)

    def parse_brace_content(self) -> str:
        """Parse {content} and return the raw content string."""
        if not self.at('lbrace'):
            # No brace â€” take the next single token
            t = self.advance()
            return t.value
        self.advance()  # skip {
        depth = 1
        parts = []
        while depth > 0:
            t = self.advance()
            if t.kind == 'lbrace':
                depth += 1
                parts.append('{')
            elif t.kind == 'rbrace':
                depth -= 1
                if depth > 0:
                    parts.append('}')
            elif t.kind == 'eof':
                break
            else:
                parts.append(t.value)
        return ''.join(parts)

    def parse_brace_group(self) -> SExp:
        """Parse {expr} as a grouped expression."""
        if not self.at('lbrace'):
            return self.parse_atom()
        self.advance()  # skip {
        expr = self.parse_expr(0)
        if self.at('rbrace'):
            self.advance()
        return expr

    def parse_paren(self) -> SExp:
        """Parse (expr) or (a, b, c) as grouping or tuple."""
        self.advance()  # skip (
        if self.at('rparen'):
            self.advance()
            return Atom('()')
        first = self.parse_expr(0)
        if self.at('comma'):
            # Tuple
            items = [first]
            while self.at('comma'):
                self.advance()
                items.append(self.parse_expr(0))
            if self.at('rparen'):
                self.advance()
            return App('tuple', items)
        if self.at('rparen'):
            self.advance()
        return first

    def parse_paren_args(self) -> list[SExp]:
        """Parse (arg1, arg2, ...) for function application."""
        self.advance()  # skip (
        if self.at('rparen'):
            self.advance()
            return []
        args = [self.parse_expr(0)]
        while self.at('comma'):
            self.advance()
            args.append(self.parse_expr(0))
        if self.at('rparen'):
            self.advance()
        return args

    def parse_environment(self) -> SExp:
        r"""Parse \begin{env}...\end{env}. For arrays, extract structure."""
        env_name = self.parse_brace_content()
        if env_name == 'array':
            return self.parse_array()
        # Generic: skip until \end{env_name}
        depth = 1
        while depth > 0:
            t = self.advance()
            if t.kind == 'eof':
                break
            if t.kind == 'command' and t.value == 'begin':
                self.parse_brace_content()
                depth += 1
            elif t.kind == 'command' and t.value == 'end':
                self.parse_brace_content()
                depth -= 1
        return Atom(f'[{env_name}]')

    def parse_array(self) -> SExp:
        """Parse array environment content, extract arrows as graph edges."""
        # Skip column spec {c} or {ccc} etc.
        if self.at('lbrace'):
            self.parse_brace_content()
        # Collect all tokens in each row (separated by \\) until \end{array}
        edges = []
        current_row: list[SExp] = []
        while True:
            t = self.peek()
            if t.kind == 'eof':
                break
            if t.kind == 'command' and t.value == 'end':
                self.advance()
                self.parse_brace_content()
                break
            if t.kind == 'newline':
                # Row separator \\
                self.advance()
                if current_row:
                    edges.extend(self._extract_row_arrows(current_row))
                    current_row = []
                continue
            # In array context, collect ops and atoms individually
            if t.kind == 'op':
                self.advance()
                current_row.append(Atom(t.value))
            elif t.kind == 'ident':
                self.advance()
                current_row.append(Atom(t.value))
            elif t.kind == 'command':
                node = self.parse_command()
                if str(node):
                    current_row.append(node)
            else:
                self.advance()  # skip unknown tokens in array
        if current_row:
            edges.extend(self._extract_row_arrows(current_row))
        if edges:
            return App('graph', edges)
        return Atom('[array]')

    def _extract_row_arrows(self, items: list[SExp]) -> list[SExp]:
        """From a row of [â€¢, â†’, â€¢] extract (â†’ â€¢ â€¢) edges."""
        edges = []
        arrow_syms = {'â†’', 'â†', 'â†“', 'â†‘', 'â‡‰', 'â†”', 'â‡’', 'â‡'}
        i = 0
        while i < len(items):
            s = str(items[i])
            if s in arrow_syms and i > 0 and i < len(items) - 1:
                edges.append(App(s, [items[i - 1], items[i + 1]]))
                i += 2
            else:
                i += 1
        return edges


class ParseError(Exception):
    pass


# ---------------------------------------------------------------------------
# Public API
# ---------------------------------------------------------------------------

def parse(latex: str) -> str:
    """Parse a LaTeX math expression into an s-expression string.

    Returns the s-exp as a string. For unparseable input, returns the
    LaTeX wrapped in quotes as a fallback.
    """
    latex = latex.strip()
    if not latex:
        return '""'
    try:
        tokens = tokenize(latex)
        parser = Parser(tokens)
        result = parser.parse_expr(0)
        return str(result)
    except (ParseError, IndexError, RecursionError):
        return f'"{latex}"'


def parse_tree(latex: str) -> SExp:
    """Parse a LaTeX math expression into an s-expression AST."""
    tokens = tokenize(latex)
    parser = Parser(tokens)
    return parser.parse_expr(0)


def parse_all(html: str) -> list[dict]:
    """Extract and parse all $...$ and $$...$$ from an HTML string.

    Returns a list of dicts: {latex, display, sexp, position}.
    """
    results = []
    # Display math first (greedy match)
    for m in re.finditer(r'\$\$(.+?)\$\$', html, re.DOTALL):
        tex = m.group(1).strip()
        results.append({
            'latex': tex,
            'display': True,
            'sexp': parse(tex),
            'position': m.start(),
        })
    # Inline math (avoid matching inside $$...$$)
    display_ranges = [(m.start(), m.end())
                      for m in re.finditer(r'\$\$.+?\$\$', html, re.DOTALL)]
    for m in re.finditer(r'\$([^$\n]+?)\$', html):
        if any(s <= m.start() < e for s, e in display_ranges):
            continue
        tex = m.group(1).strip()
        results.append({
            'latex': tex,
            'display': False,
            'sexp': parse(tex),
            'position': m.start(),
        })
    results.sort(key=lambda r: r['position'])
    return results
