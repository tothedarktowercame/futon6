\chapter*{Introduction: The Making of the First-Proof Cycle}
\addcontentsline{toc}{chapter}{Introduction: The Making of the First-Proof Cycle}

\section*{Highlights}
\begin{itemize}[leftmargin=1.5em]
\item Dependency-graph representations of proofs enabled local gap isolation and targeted repair across all ten problems.
\item Node-level verification with predecessor/successor context improved calibration relative to whole-draft review.
\item Adversarial critic--responder iteration converted early overclaims into explicit closed, partial, or conditional outcomes.
\item Targeted computational stress tests constrained speculative branches, especially in the \(n=4\) branch of Problem~4.
\item Structured handoff memos preserved unresolved obligations as named, testable next steps rather than implicit deferrals.
\end{itemize}

\section*{Snapshot}
\begin{itemize}[leftmargin=1.5em]
\item Ten initial proof attempts drafted in under two hours.
\item Over two hundred commits across roughly 55~hours wall-clock (February 11--13, 2026), in addition to earlier infrastructure development.
\item A shift in framing over the course of the sprint: from an early ``all solved'' posture to a clearer partition into proved, conditional, and partial results.
\item A methodological lesson: wiring-diagram--based verification localized gaps and inconsistencies more effectively than plain narrative drafting.
\end{itemize}

\section*{Materials and Methods}
\begin{itemize}[leftmargin=1.5em]
\item \textbf{Model/runtime split.} Claude Max runs on a remote Linode host; Codex Pro runs on the local laptop workspace (\texttt{/home/joe/code/futon6}).
\item \textbf{Software/toolchain summary.} Computational checks used Python~3 scripts with NumPy/SciPy for numerical linear algebra and optimization, SymPy for symbolic algebra (resultants, Sturm sequences, Gr\"obner bases), mpmath for selected high-precision checks, PHCpack via \texttt{phcpy} for polynomial-system solving/certification in Problem~4 (Case~3c), and cvxpy for SDP-based sum-of-squares certificate attempts. Proof-structure analysis used wiring-diagram generators (nine scripts producing JSON and Mermaid flowcharts via the internal \texttt{thread\_performatives} module) and \texttt{validate-ct.py} for classical NER and scope extraction over PlanetMath entries. Pattern tagging and term spotting used Babashka (Clojure) scripts operating on EDN data formats. Document production used \LaTeX{} (\texttt{pdflatex}) with repository consistency-checking scripts (\texttt{check-latex-syntax-violations.py}, \texttt{check-ratchet-fixedw-typesetting.py}).
\item \textbf{Codex Pro token accounting (local, log-derived).} From \texttt{\~{}/.codex/sessions/*} telemetry (records where the event type is \emph{token\_count}), over the 50-hour window ending 2026-02-13 21:41 UTC (window start: 2026-02-11 19:41 UTC), there were 333 futon6-related Codex rollout traces out of 334 local rollout traces (99.7\%). Aggregated futon6 usage totals: total tokens 965{,}714{,}475; input tokens 961{,}719{,}044 (including cached input tokens 912{,}686{,}208, so non-cached input \(\approx 49{,}032{,}836\)); output tokens 3{,}995{,}431; reasoning-output tokens 2{,}072{,}289.
\item \textbf{Claude Max token accounting (Linode, log-derived).} From \texttt{\~{}/.claude/projects/*/} session files on the Linode host, 9 futon6-related Claude~Code sessions were identified (8 contributing within the 50-hour Codex-comparable window). Over the same 50-hour window ending 2026-02-13 21:41 UTC (window start: 2026-02-11 19:41 UTC), aggregated futon6 usage totals: total tokens 791{,}980{,}382; input tokens 789{,}643{,}774 (including cached-read input tokens 752{,}300{,}790, cache-creation input tokens 37{,}221{,}978, non-cached input \(\approx 121{,}006\)); output tokens 2{,}336{,}608. Model: \texttt{claude-opus-4-6} (7{,}754 assistant messages). Full-window totals (9~sessions, 2026-02-08 through 2026-02-13): total tokens 1{,}021{,}665{,}524; output tokens 2{,}798{,}074.
\end{itemize}

\section*{Introduction}
This monograph records both the mathematical results and the working process
behind a compressed, multi-agent proof cycle in \texttt{futon6}.\footnote{Source repository: \url{https://github.com/tothedarktowercame/futon6}} The project
began as infrastructure---knowledge ingestion, tagging, and wiring-diagram
metatheory---and then pivoted into a rapid proof sprint with iterative
critique and repair.

The working process turned out to resemble Lakatos's \emph{Proofs and
Refutations}~\cite{lakatos1976} more than we expected. In Lakatos's
dialogue, a conjecture is proposed, counterexamples surface, the conjecture
is patched, and the cycle repeats---with each iteration sharpening both the
theorem and the participants' understanding of the domain. Our sprint
followed the same rhythm, except that the interlocutors were a human
dispatcher, multiple Claude instances (provers), and Codex (critic and
research assistant). Conjectures were drafted quickly; adversarial review
surfaced overclaims and gaps; targeted repair narrowed the open obligations.
The wiring-diagram decomposition---which represents each proof as a typed
graph of claims and dependencies---served as the shared epistemic artefact
that Lakatos's blackboard served in his fictional classroom.

The title alludes to the sprint format: ten open problems attempted in
roughly 55~hours wall-clock, with the process documented alongside the results.
The Lakatosian connection runs through Pease et
al.~\cite{pease2017}, which formalised Lakatos's informal logic of
mathematical discovery as a dialogue game over argumentation structures,
implemented in a system capable of mixed-initiative human--AI collaboration.
That paper asked whether computers could participate in mathematical
reasoning the way humans do---through conjecture, critique, and reform.
The present work is, in a sense, a large-scale empirical answer: ten
problems attempted by AI agents under human supervision, with the
Lakatosian cycle running at machine speed.

This connection is not accidental. Corneli et al.~\cite{corneli2017}
developed a computational model of mathematical question-and-answer dialogues
grounded in Lakatos's framework, using Inference Anchoring Theory + Content
(IATC) to annotate MathOverflow threads with performative types
(assert, challenge, reform, clarify, etc.). The IATC vocabulary reappears in
this project's Stage~7 thread-wiring pipeline (see Part~III, Act~VI), where
StackExchange threads are parsed into wiring diagrams whose edges carry the
same performative labels. The earlier work on peer-produced mathematical
knowledge~\cite{corneli2013} established the empirical base: PlanetMath as a
community-maintained proof ecosystem, studied through the lens of paragogy
(peer-produced peer learning). The present sprint can be read as a
machine-accelerated instance of the same phenomenon: collaborative,
incremental proof construction with explicit argumentation structure.

The working notes reveal a consistent asymmetry: generation is fast;
trustworthy validation is slow. This is the same asymmetry Lakatos
identified in his classroom: conjectures are cheap, but understanding
\emph{why} a conjecture fails (or holds) is the real mathematical work.
In practice, the strongest leverage came from structured verification---tools
that made weaknesses visible early and locally.

\section*{Reader Guide}
This document is organized in five parts.

\begin{itemize}[leftmargin=1.5em]
\item \textbf{Part I (Annotated Overview):} short, citation-rich introductions for Problems 1--10, intended as navigational summaries.
\item \textbf{Part II (Full Proof Drafts):} expanded writeups imported from the solution files, suitable as the base for a longer manuscript (targeting roughly book-length exposition). Coloured boxes separate the proof proper from process annotations (dead paths, revisions, open obligations).
\item \textbf{Part III (Prompt Excerpts and Pivot Moments):} curated source excerpts (prompts and dispatch/history snippets) that document key decision points and proof-state transitions.
\item \textbf{Part IV (Proof Patterns):} a cross-problem analysis of strategy patterns---what worked (layer-switching, creative reduction, structural decomposition), what didn't (the TryHarder loop), and how a coaching intervention broke a stuck problem open.
\item \textbf{Part V (Color Plates):} syntax-coloured renderings of the proof files, produced by automated math-mode normalization.
\end{itemize}

\section*{Terminology}
\begin{description}[leftmargin=1.5em,style=nextline]
\item[AIF] Active Inference Framework---used here as a conceptual lens for agent roles, intervention points, and coordination state; a full AIF policy loop for proof search is proposed future work, not yet implemented in this sprint.
\item[BSS] Batson--Spielman--Srivastava spectral sparsification framework.
\item[IATC] Inference Anchoring Theory + Content---an annotation scheme for mathematical dialogues used here to type dialogue moves and content links within the AIF process model~\cite{corneli2017}.
\item[MSS] Marcus--Spielman--Srivastava interlacing families framework.
\item[PSD] Positive semi-definite (for matrices).
\end{description}

\section*{Current Status}
\noindent\textbf{Status legend.}
Each problem is tagged on two axes:
\textbf{Closed/Partial/Conditional} for mathematical status and
\textbf{Validation-complete/Partial validation} for QC-validation status.

\medskip
\noindent\textbf{Outcome summary.}
Problem~3 is closed for the scoped existence target and validation-complete;
Problem~5 is closed in a scope-limited form;
Problem~10 is conditional under stated assumptions;
Problems~4 and~6 are partial with explicit remaining obligations;
Problem~7 is provisionally closed mathematically (rotation route), with QC
review still active; and Problems~1,~2,~7,~8, and~9 are partial-validation at
node level due to unresolved verifier gaps.

\begin{itemize}[leftmargin=1.5em]
\item Problems 1, 2, 8, and 9 now have node-level validation artifacts.\footnote{Per-problem verifier outputs are tracked in \url{https://github.com/tothedarktowercame/futon6/tree/master/data/first-proof} under filenames matching \texttt{problem*-codex-results.jsonl}.} Each currently remains in \emph{partial validation} due to unresolved node-level gaps flagged by the verifier.
\item Problem 7 is treated as provisionally closed mathematically via the rotation route, while remaining in \emph{partial validation} at QC level pending independent ledger re-check and closure of verifier-flagged nodes.
\item Problem 3 now has a validation-complete existence path under the scoped criterion used here (current run: 2 verified, 7 plausible, 0 gaps). Uniqueness/irreducibility is treated as optional and out of scope for the core existence claim.
\item Problem 10 is conditional under explicitly stated assumptions, with explicit necessity counterexamples for assumption violations.
\item Problem 5 is solved in a scope-limited form for $F_O$-local connective spectra.
\item Problem 6 is partial: the $K_n$ case is proved ($c_0 = 1/3$), with one remaining technical gap in the general-graph argument (formal $\bar{d} < 1$ bound at $M_t \ne 0$).
\item Problem 4 is partial: proved analytically for $n \le 3$; the $n=4$ branch has strong computational support with one certification step still pending; higher $n$ remains open.
\item Cross-problem closure-vs-validation inventory.\footnote{\url{https://github.com/tothedarktowercame/futon6/blob/master/data/first-proof/closure-validation-audit.md}}
\end{itemize}
