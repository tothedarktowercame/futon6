\clearpage
\section*{Highlights}
\begin{itemize}[leftmargin=1.5em]
\item Dependency-graph representations of proofs enabled local gap isolation and targeted repair across all ten problems.
\item Node-level verification with predecessor/successor context improved calibration relative to whole-draft review.
\item Adversarial critic--responder iteration converted early overclaims into explicit closed, partial, or conditional outcomes.
\item Targeted computational stress tests constrained speculative branches, especially in the \(n=4\) branch of Problem~4.
\item Structured handoff memos preserved unresolved obligations as named, testable next steps rather than implicit deferrals.
\end{itemize}

\section*{Snapshot}
\begin{itemize}[leftmargin=1.5em]
\item Ten initial proof attempts drafted in under two hours.
\item Over two hundred commits across roughly 55~hours wall-clock (February 11--13, 2026), in addition to earlier infrastructure development.
\item A shift in framing over the course of the sprint: from an early ``all solved'' posture to a clearer partition into proved, conditional, and partial results.
\item A methodological lesson: wiring-diagram--based verification localized gaps and inconsistencies more effectively than plain narrative drafting.
\end{itemize}

\section*{Materials and Methods}
\begin{itemize}[leftmargin=1.5em]
\item \textbf{Model/runtime split.} Claude Max runs on a remote Linode host; Codex Pro runs on the local laptop workspace (\texttt{/home/joe/code/futon6}).
\item \textbf{Software/toolchain summary.} Computational checks used Python 3 scripts with NumPy/SciPy for numerical linear algebra and optimization, SymPy for symbolic algebra, mpmath for selected high-precision checks, and PHCpack via \texttt{phcpy} for polynomial-system solving/certification in Problem~4 (Case~3c). Document production and consistency checks used LaTeX (\texttt{pdflatex}) and repository scripts (including \texttt{check-latex-text-truth.py}, wiring-diagram generators, and \texttt{validate-ct.py}).
\item \textbf{Codex Pro token accounting (local, log-derived).} From \texttt{\~{}/.codex/sessions/*} telemetry (records where the event type is \emph{token\_count}), over the 50-hour window ending 2026-02-13 21:41 UTC (window start: 2026-02-11 19:41 UTC), there were 333 futon6-related Codex rollout traces out of 334 local rollout traces (99.7\%).

\begin{center}
\small
\begin{tabular}{@{}lrrc@{}}
\toprule
Metric & Total & Per rollout (avg) & \% of total \\
\midrule
\textbf{Total tokens} & 965{,}714{,}475 & 2{,}900{,}043 & 100\% \\
\textbf{Input tokens (all)} & 961{,}719{,}044 & 2{,}887{,}445 & 99.6\% \\
\quad Cached input & 912{,}686{,}208 & 2{,}740{,}800 & 94.5\% \\
\quad Non-cached input & 49{,}032{,}836 & 147{,}246 & 5.1\% \\
\textbf{Output tokens} & 3{,}995{,}431 & 11{,}997 & 0.4\% \\
\textbf{Reasoning-output tokens} & 2{,}072{,}289 & 6{,}223 & --- \\
\bottomrule
\end{tabular}
\normalsize
\end{center}
Interpretation (inference): the large cached-input share likely reflects repeated reuse of stable local context across rollouts, including processed Math StackExchange/MathOverflow corpora and derived prompt artifacts (e.g., \texttt{se-data/math-processed}, \texttt{math-se-processed}/\texttt{mo-processed}, and \texttt{--math-se-dir} workflows in the Codex proof-polish scripts).
\item \textbf{Claude Max token accounting (Linode, log-derived).} From \texttt{\~{}/.claude/projects/*/} session files on the Linode host, 9 futon6-related Claude~Code sessions were identified (8 contributing within the 50-hour Codex-comparable window). Over the same 50-hour window ending 2026-02-13 21:41 UTC (window start: 2026-02-11 19:41 UTC), aggregated futon6 usage totals: total tokens 791{,}980{,}382; input tokens 789{,}643{,}774 (including cached-read input tokens 752{,}300{,}790, cache-creation input tokens 37{,}221{,}978, non-cached input \(\approx 121{,}006\)); output tokens 2{,}336{,}608. Model: \texttt{claude-opus-4-6} (7{,}754 assistant messages). Full-window totals (9~sessions, 2026-02-08 through 2026-02-13): total tokens 1{,}021{,}665{,}524; output tokens 2{,}798{,}074.
\end{itemize}

\section*{Introduction}
This monograph records both the mathematical results and the working process
behind a compressed, multi-agent proof cycle in \texttt{futon6}.\footnote{Source repository: \url{https://github.com/tothedarktowercame/futon6}} The project
began as infrastructure---knowledge ingestion, tagging, and wiring-diagram
metatheory---and then pivoted into a rapid proof sprint with iterative
critique and repair.

The working process turned out to resemble Lakatos's \emph{Proofs and
Refutations}~\cite{lakatos1976} more than we expected. In Lakatos's
dialogue, a conjecture is proposed, counterexamples surface, the conjecture
is patched, and the cycle repeats---with each iteration sharpening both the
theorem and the participants' understanding of the domain. Our sprint
followed the same rhythm, except that the interlocutors were a human
dispatcher, multiple Claude instances (provers), and Codex (critic and
research assistant). Conjectures were drafted quickly; adversarial review
surfaced overclaims and gaps; targeted repair narrowed the open obligations.
The wiring-diagram decomposition---which represents each proof as a typed
graph of claims and dependencies---served as the shared epistemic artefact
that Lakatos's blackboard served in his fictional classroom.

The title alludes to the sprint format: ten open problems attempted in
roughly 55~hours wall-clock, with the process documented alongside the results.
The Lakatosian connection runs through Pease et
al.~\cite{pease2017}, which formalised Lakatos's informal logic of
mathematical discovery as a dialogue game over argumentation structures,
implemented in a system capable of mixed-initiative human--AI collaboration.
That paper asked whether computers could participate in mathematical
reasoning the way humans do---through conjecture, critique, and reform.
The present work is, in a sense, a large-scale empirical answer: ten
problems attempted by AI agents under human supervision, with the
Lakatosian cycle running at machine speed.

This connection is not accidental. Corneli et al.~\cite{corneli2017}
developed a computational model of mathematical question-and-answer dialogues
grounded in Lakatos's framework, using Inference Anchoring Theory + Content
(IATC) to annotate MathOverflow threads with performative types
(assert, challenge, reform, clarify, etc.). The IATC vocabulary reappears in
this project's Stage~7 thread-wiring pipeline (see Part~III, Act~VI), where
StackExchange threads are parsed into wiring diagrams whose edges carry the
same performative labels. The earlier work on peer-produced mathematical
knowledge~\cite{corneli2013} established the empirical base: PlanetMath as a
community-maintained proof ecosystem, studied through the lens of paragogy
(peer-produced peer learning). The present sprint can be read as a
machine-accelerated instance of the same phenomenon: collaborative,
incremental proof construction with explicit argumentation structure.

The working notes reveal a consistent asymmetry: generation is fast;
trustworthy validation is slow. This is the same asymmetry Lakatos
identified in his classroom: conjectures are cheap, but understanding
\emph{why} a conjecture fails (or holds) is the real mathematical work.
In practice, the strongest leverage came from structured verification---tools
that made weaknesses visible early and locally.

\section*{Current Status}
\noindent\textbf{Outcome summary (status code [M|V]).} \(\mathbf{M}\in\{\mathbf{C},\mathbf{P},\mathbf{?}\}\) with \(\mathbf{C}=\)closed, \(\mathbf{P}=\)partial, \(\mathbf{?}=\)conditional; \(V\in\{\checkmark,\sim,\mathbf{?}\}\) with \(\checkmark=\)validation-complete, \(\sim=\)partial validation, \(\mathbf{?}=\)not yet fully validated.

\begin{itemize}[leftmargin=1.5em]
\item \textbf{P1, P2, P8, P9 [P|\(\sim\)].} Node-level validation artifacts exist,\footnote{Per-problem verifier outputs are tracked in \url{https://github.com/tothedarktowercame/futon6/tree/master/data/first-proof} under filenames matching \texttt{problem*-codex-results.jsonl}.} but unresolved verifier gaps remain.
\item \textbf{P7 [C|\(\sim\)].} Provisionally closed mathematically via the rotation route; QC validation remains open pending independent ledger re-check and closure of flagged nodes.
\item \textbf{P3 [C|\(\checkmark\)].} Validation-complete existence path under the scoped criterion (current run: 2 verified, 7 plausible, 0 gaps). Uniqueness/irreducibility is treated as optional and out of scope for the core existence claim.
\item \textbf{P5 [C|?].} Solved in a scope-limited form for $F_O$-local connective spectra.
\item \textbf{P6 [P|?].} $K_n$ case proved ($c_0 = 1/3$); one technical gap remains in the general-graph argument (formal $\bar{d} < 1$ bound at $M_t \ne 0$).
\item \textbf{P4 [P|?].} Proved analytically for $n \le 3$; the $n=4$ branch has strong computational support with one certification step pending; higher $n$ remains open.
\item \textbf{P10 [?|?].} Conditional under explicitly stated assumptions, with explicit necessity counterexamples for assumption violations.
\item Cross-problem closure-vs-validation inventory.\footnote{\url{https://github.com/tothedarktowercame/futon6/blob/master/data/first-proof/closure-validation-audit.md}}
\end{itemize}

\par
\normalcolor
\section*{Materials and Methods}
\begin{itemize}[leftmargin=1.5em]
\item \textbf{Model/runtime split.} Claude Max runs on a remote Linode host; Codex Pro runs on the local laptop workspace (\texttt{/home/joe/code/futon6}).
\item \textbf{Software/toolchain summary.} Computational checks used Python 3 scripts with NumPy/SciPy for numerical linear algebra and optimization, SymPy for symbolic algebra, mpmath for selected high-precision checks, and PHCpack via \texttt{phcpy} for polynomial-system solving/certification in Problem~4 (Case~3c). Document production and consistency checks used LaTeX (\texttt{pdflatex}) and repository scripts (including \texttt{check-latex-text-truth.py}, wiring-diagram generators, and \texttt{validate-ct.py}).
\item \textbf{Codex Pro token accounting (local, log-derived).} From local Codex session telemetry (\path{~/.codex/sessions/*}, event type \emph{token\_count}), over the 50-hour window ending 2026-02-13 21:41 UTC (window start: 2026-02-11 19:41 UTC), there were 333 futon6-related Codex rollout traces out of 334 local rollout traces (99.7\%).

\begin{center}
\small
\begin{tabular}{@{}lrrc@{}}
\toprule
Metric & Total & Per rollout (avg) & \% of total \\
\midrule
\textbf{Total tokens} & 965{,}714{,}475 & 2{,}900{,}043 & 100\% \\
\textbf{Input tokens (all)} & 961{,}719{,}044 & 2{,}887{,}445 & 99.6\% \\
\quad Cached input & 912{,}686{,}208 & 2{,}740{,}800 & 94.5\% \\
\quad Non-cached input & 49{,}032{,}836 & 147{,}246 & 5.1\% \\
\textbf{Output tokens} & 3{,}995{,}431 & 11{,}997 & 0.4\% \\
\textbf{Reasoning-output tokens} & 2{,}072{,}289 & 6{,}223 & --- \\
\bottomrule
\end{tabular}
\normalsize
\end{center}
Interpretation (inference): the large cached-input share likely reflects repeated reuse of stable local context across rollouts, including processed Math StackExchange/MathOverflow corpora and derived prompt artifacts such as \path{se-data/math-processed}, \path{math-se-processed}, \path{mo-processed}, and Codex workflows using \path{--math-se-dir}.

\item \textbf{Claude Max token accounting (Linode, log-derived).} From Linode session files (\path{~/.claude/projects/*/}), 9 futon6-related Claude~Code sessions were identified; 8 sessions contributed within the 50-hour Codex-comparable window ending 2026-02-13 21:41 UTC.

\begin{center}
\small
\begin{tabular}{@{}lrrc@{}}
\toprule
Metric & Total & Per session (avg) & \% of total \\
\midrule
\textbf{Total tokens (50h window)} & 791{,}980{,}382 & 98{,}997{,}548 & 100\% \\
\textbf{Input tokens (all)} & 789{,}643{,}774 & 98{,}705{,}472 & 99.7\% \\
\quad Cached-read input & 752{,}300{,}790 & 94{,}037{,}599 & 95.0\% \\
\quad Cache-creation input & 37{,}221{,}978 & 4{,}652{,}747 & 4.7\% \\
\quad Non-cached input & 121{,}006 & 15{,}126 & 0.0\% \\
\textbf{Output tokens} & 2{,}336{,}608 & 292{,}076 & 0.3\% \\
\bottomrule
\end{tabular}
\normalsize
\end{center}
Model: \texttt{claude-opus-4-6}; assistant messages: 7{,}754. Full-window totals (9 sessions, 2026-02-08 through 2026-02-13): total tokens 1{,}021{,}665{,}524; output tokens 2{,}798{,}074.
\end{itemize}

\clearpage
\normalcolor
\section*{Reader Guide}
This document is organized in five parts.

\begin{itemize}[leftmargin=1.5em]
\item \textbf{Part I (Annotated Overview):} short, citation-rich introductions for Problems 1--10, intended as navigational summaries.
\item \textbf{Part II (Full Proof Drafts):} expanded writeups imported from the solution files, suitable as the base for a longer manuscript (targeting roughly book-length exposition). Coloured boxes separate the proof proper from process annotations (dead paths, revisions, open obligations).
\item \textbf{Part III (Prompt Excerpts and Pivot Moments):} curated source excerpts (prompts and dispatch/history snippets) that document key decision points and proof-state transitions.
\item \textbf{Part IV (Proof Patterns):} a cross-problem analysis of strategy patterns---what worked (layer-switching, creative reduction, structural decomposition), what didn't (the TryHarder loop), and how a coaching intervention broke a stuck problem open.
\item \textbf{Part V (Color Plates):} syntax-coloured renderings of the proof files, produced by automated math-mode normalization.
\end{itemize}

\section*{Terminology}
\begin{description}[leftmargin=1.5em,style=nextline]
\item[AIF] Active Inference Framework---used here as a conceptual lens for agent roles, intervention points, and coordination state; a full AIF policy loop for proof search is proposed future work, not yet implemented in this sprint.
\item[BSS] Batson--Spielman--Srivastava spectral sparsification framework.
\item[IATC] Inference Anchoring Theory + Content---an annotation scheme for mathematical dialogues used here to type dialogue moves and content links within the AIF process model~\cite{corneli2017}.
\item[MSS] Marcus--Spielman--Srivastava interlacing families framework.
\item[PSD] Positive semi-definite (for matrices).
\end{description}
