\chapter{Strategy Patterns Across Ten Problems}

The ten proofs in Part~II were not produced by a uniform method.
Some closed quickly; others required layer-switching, creative
reductions, or honest declarations of conditionality.
This chapter extracts the transferable strategy patterns---what
worked, what didn't, and what an agent stuck on one problem
could learn from the successes of another.

\section{Three Sprint Outcomes}

Every open problem in a sprint has one of three honest outcomes:

\begin{enumerate}
\item \textbf{Closed.} A complete proof (possibly with minor caveats).
  Problems 1--5, 7--10; Problem~6 for $K_n$ (with a narrow technical
  gap for general graphs).
\item \textbf{Reduced.} A conditional result with clearly stated
  assumptions.
\item \textbf{Mapped.} The obstruction is characterized and adjacent
  problems are identified, but no proof is offered.
\end{enumerate}

All three are legitimate outcomes. Outcome~2 is not a defect of
outcome~1; it is a different kind of contribution.  The failure mode
is treating outcome~2 as something to repair rather than something
to state clearly.  Problem~6 spent eight hours as outcome~2 before
a coaching intervention moved it to outcome~1---the layer switch,
not additional effort, made the difference.

\section{Success Pattern: Layer-Switching (Problem 7)}

Problem~7 (uniform lattice with 2-torsion) is the clearest example
of a successful strategy pivot.

\begin{description}
\item[Initial approach:] Reflection lattice in even dimension.
  The E2 obligation (Fowler's criterion) was discharged.
\item[Obstruction:] The surgery obligation (S) was blocked.
  Equivariant surgery requires a codimension-2 gap hypothesis;
  reflections give codimension-1 fixed sets.  Blocked.
  (\texttt{0fa4e82}: ``restructure S-branch as open problem with three approaches'')
\item[Characterization:] Instead of pushing harder on reflections,
  the obstruction was characterized structurally: a dimension-parity
  tension between E2 (needs even $n$) and S (better in odd $n$).
\item[Layer switch:] Replace reflections (codimension~1) with rotations
  (codimension~2).  Now $n$ is odd, E2 still works (fixed set has
  odd dimension, $\chi = 0$), and the codimension-2 gap hypothesis
  is satisfied.
  (\texttt{287a41c}: ``rotation route (Approach~IV), paper reads, triage'';
   \texttt{620ed57}: ``resolve rotation lattice existence, discharge E2'')
\item[Closure:] The surgery obstruction vanishes (trivial normal
  bundle from the congruence condition).
  (\texttt{8ce9771}: ``flat-normal-bundle argument---rational obstruction vanishes'';
   \texttt{158bc4f}: ``integral obstruction vanishes---obligation~S discharged'')
\end{description}

\textbf{Transferable principle:} When blocked in one layer,
characterize the obstruction structurally before attempting to
overcome it.  The characterization may reveal that a different
layer avoids the obstruction entirely.

\section{Success Pattern: Creative Reduction (Problem 4)}

Problem~4 (root separation under finite free convolution)
progressed from numerical evidence to proof via a sequence
of reductions:

\begin{enumerate}
\item Centering reduction (translation invariance of $\Phi_n$).
\item For $n = 3$: discovery of the identity
  $\Phi_3 \cdot \mathrm{disc} = 18 \, a_2^2$ (exact, verified symbolically).
\item Recognition that the surplus expression has the form
  required by Titu's lemma (Engel form of Cauchy--Schwarz).
\end{enumerate}

Step~2 was the creative step---an identity discovered numerically
and verified symbolically
(\texttt{9db6b4f}: ``Haar orbit exploration and key identity finding'';
 \texttt{0003300}: ``Prove P4 superadditivity for $n=3$ via $\Phi_3 \cdot \mathrm{disc}$
 identity + Cauchy--Schwarz'').
The key was that the identity was
\emph{sought} because the reduction strategy demanded an algebraic
relationship between $\Phi_n$ and known invariants.  The strategy
shaped the search.  The subsequent extension to $n = 4$ followed a
different route---algebraic elimination plus computational certification
(\texttt{84c0041}: ``harden PHC parsing and record $n \ge 4$ certified closure'').

\textbf{Transferable principle:} Reductions create demand for
specific identities or lemmas.  The demand makes the search
targeted rather than exploratory.

\section{Success Pattern: Structural Decomposition (Problem 8)}

Problem~8 (Lagrangian smoothing of polyhedral surfaces) was stuck
until the symplectic direct sum decomposition was discovered:
the 4-face Lagrangian condition forces $\mathbb{R}^4 = V_1 \oplus V_2$.
This single structural insight
(\texttt{09e23db}: ``symplectic direct sum forces Maslov index exactly~0'')
unlocked everything---Maslov index
vanishing, vertex smoothing via product structure
(\texttt{a5a4fbe}: ``replace crease smoothing + Lagrangian surgery with product smoothing''),
and the Hamiltonian isotopy property
(\texttt{de3e2ac}: ``justify Hamiltonian isotopy'').

\textbf{Transferable principle:} Look for structural decompositions
that simplify the problem globally, not just local fixes for individual
obstacles.

\section{From Failure to Progress: Problem 6's Layer Switch}

Problem~6 (epsilon-light subsets) is the sprint's most instructive
case study because it exhibits both patterns: a TryHarder loop
\emph{and} the layer-switch that broke it.

\subsection{Phase 1: The TryHarder Loop}

The initial approach generated six or more handoff
and dispatch documents across multiple sessions, from the initial
dispatch (\texttt{5289ca8}: ``GPL-H attack dispatch'') through
Directions~A--D (\texttt{63a23ba}, \texttt{22c091f}, \texttt{b6a7625},
\texttt{d64fd13}) to closure attempts
(\texttt{78d94bc}: ``GPL-H closure attempt---all scores $< 1$'')
and counterexamples (\texttt{cc11834}: ``$K_{t,r}$ counterexample'').
The pattern:

\begin{enumerate}
\item Identify the gap (Assumption~V: vertex-induced selection).
\item Attempt closure via a specific attack vector.
\item Fail.
\item Generate a new handoff document dispatching another attack.
\item Repeat from step~2.
\end{enumerate}

All closure attempts targeted the sparsification layer (adapting
Batson--Spielman--Srivastava edge sparsification to vertex selection)
without recognizing that the obstruction there might be structural---not a
gap to fill but a genuine mismatch between edge and vertex selection.

\subsection{The coaching intervention}

A human coaching prompt forced layer enumeration:

\begin{quote}
\emph{What kind of problem is this?  What kind of proof applies?
How would you teach it to an undergraduate?  What kind of person
finds this easy?  Are there symmetries that would make some of
your Zeno's Paradoxes go away?}
\end{quote}

Each question targets a specific reframing:

\begin{description}
\item[``What kind of problem?''] Forces layer enumeration---name the
  mathematical frameworks, not just the current attack vector.
\item[``Teach it to an undergraduate?''] Forces identification of
  what is \emph{elementary} about the problem.  The elementary core
  is often the proof.
\item[``Who finds this easy?''] Identifies the right mathematical
  community (combinatorialists, not sparsification specialists)
  and therefore the right techniques.
\item[``Symmetries / Zeno's Paradoxes?''] Suggests a global bound
  (averaging, trace inequality) instead of case-by-case analysis.
\end{description}

\subsection{Phase 2: The elementary proof}

After 15 minutes of thinking, the agent found a proof chain that
bypasses the sparsification layer entirely:

\begin{enumerate}
\item \textbf{Tur\'an's theorem} gives an independent set $I_0$
  with $|I_0| \ge \varepsilon n/3$ in the heavy-edge subgraph.
  All edges internal to $I_0$ are light ($\tau_e \le \varepsilon$).
\item \textbf{Barrier greedy}: at each step, pick the vertex $v$
  with minimum $\|Y_t(v)\|$.
\item \textbf{PSD trace bound}: $\|Y\| \le \operatorname{tr}(Y)$
  for any PSD matrix~$Y$.
\item \textbf{Pigeonhole}: if the average trace
  $\bar{d}_t = \frac{1}{r_t}\sum_v \operatorname{tr}(Y_t(v)) < 1$,
  then some $v$ has $\operatorname{tr}(Y_t(v)) < 1$, therefore
  $\|Y_t(v)\| < 1$, therefore the barrier is maintained.
\end{enumerate}

For $K_n$: $\bar{d}_t = 2t/(n\varepsilon)$, so at $T = \varepsilon n/3$
steps, $\bar{d}_T = 2/3 < 1$.  This gives $|S| = \varepsilon n/3$
with $c = 1/3$, \textbf{proved exactly}.

\subsection{Phase 3: The partial averages breakthrough}

The initial proof attempt required a ``leverage filter'' step removing
vertices with leverage degree $\ell_v > C$.  This created an
irreconcilable tension: the Markov bound needed $C > 2$ to retain
enough vertices, but $\bar{d} < 1$ needed $C < 2$.  Testing on
$K_{a,b}$ confirmed this was not just a technical gap---up to $80\%$
of $I_0$ can have $\ell_v \ge 2$.

The resolution came from switching from a \emph{maximum-based} bound
to a \emph{sum-based} bound.  The \textbf{partial averages inequality}
observes that the average of the $T$ smallest leverage degrees cannot
exceed the overall average:
\[
  \frac{1}{T}\sum_{k=1}^{T} \ell_{(k)}
    \;\le\; \operatorname{avg}(\ell)
    \;<\; 2 \quad\text{(Foster on $I_0$)}.
\]
A ``min-$\ell$ greedy'' that selects vertices in order of increasing
leverage degree therefore accumulates $\sum \ell < 2T$, giving
\[
  \bar{d}_t \;\le\; \frac{2/3}{1 - \varepsilon/3} \;<\; 1
  \quad\text{for all $\varepsilon \in (0,1)$,\; at $M_t = 0$.}
\]

This eliminates the leverage filter entirely---no threshold $C$ needed,
no Markov bound, no structural assumption on maximum leverage degree.

\subsection{What remains}

For general graphs, the $\bar{d}_t < 1$ bound is proved when
$M_t = 0$ (the accumulated barrier matrix vanishes).  This covers
$K_n$, $K_{a,b}$ with $a \ne b$, cycles, grids, and sparse graphs.
For dense graphs where $M_t \ne 0$, the bound is verified
numerically at all 440 nontrivial greedy steps (max
$\bar{d} = 0.714$, amplification ratio $\le 1.30$) but one
quantitative estimate---bounding the $H_t^{-1}$ amplification
when $M_t \ne 0$---remains open.

No interlacing families.  No Borcea--Br\"and\'en.  No MSS theorem.
Just Foster's theorem $+$ partial averages $+$ PSD trace bound $+$
pigeonhole $+$ Tur\'an.  A three-line argument (PSD $\to$ pigeonhole
$\to$ existence) replaces the entire real stability machinery.

\subsection{The layer analysis}

\begin{description}
\item[Spectral layer:] Bound $\|L^{+/2} L_S L^{+/2}\| \le \varepsilon$.
  \emph{Status: set up correctly (unchanged).}
\item[Combinatorial layer:] Tur\'an $+$ Foster $+$ partial averages
  $+$ barrier greedy.
  \emph{Status: \textbf{complete} for $K_n$, $K_{a,b}$, cycles,
  grids, sparse graphs.  One quantitative gap ($M_t \ne 0$
  amplification) for dense general graphs.}
\item[Sparsification layer:] Adapt BSS from edges to vertices.
  \emph{Status: \textbf{bypassed entirely}.}
\end{description}

The breakthrough was not trying harder in the sparsification layer.
It was recognizing that the combinatorial layer---which was never
attempted---offers an elementary path that avoids the structural
obstruction entirely.  The \emph{second} breakthrough (partial averages)
came from recognizing that the leverage filter's Markov-based approach
was the wrong tool---the sum of selected leverage degrees matters, not
the maximum.

\textbf{Transferable principle:} When stuck, enumerate the layers
and assess status per layer.  Do not repeatedly attack the same
blocked layer.  Ask: ``What kind of problem is this?  Who would
find it easy?  What is the undergraduate proof?''

\section{Cross-Problem Learning}

An agent working on Problem~6 that could see Problem~7's history
would find: \emph{Problem~7 was blocked in one layer (codimension-1
surgery), characterized the obstruction, switched to a different
layer (codimension-2 surgery), and closed.}  This is directly
transferable advice.

More generally, the proof patterns across the ten problems suggest
a strategy checklist for open problems:

\begin{enumerate}
\item \textbf{Enumerate layers.}  What are the distinct mathematical
  frameworks in which this problem can be stated?
\item \textbf{Find the reduction in each layer.}  What does the problem
  reduce to from each perspective?
\item \textbf{Assess status per layer.}  Which reductions are complete,
  partial, or blocked?
\item \textbf{Characterize obstructions.}  For blocked layers, is the
  obstruction structural or technical?  Is there a known workaround?
\item \textbf{Look for analogues.}  Which other problems had a similar
  layer profile?  What strategy succeeded there?
\item \textbf{Decide the outcome.}  Is closure feasible from any layer?
  If not, state the conditional result and the open assumptions.
\end{enumerate}

This is case-based reasoning applied to proof strategy.  The ``cases''
are the other problems in the sprint (or, with a larger corpus, the
indexed literature).  The transfer is at the strategy level, not the
mathematical level---it is not that Problem~7's rotation trick applies
to Problem~6, but that Problem~7's \emph{layer-switching} strategy
might.

\section{Learning from Success, Not Just Failure}

A recurring theme: the sessions that closed problems did so by
finding the right \emph{frame}, not by working harder within
the wrong one.  Problem~7 switched from reflections to rotations.
Problem~4 found an identity that restructured the algebra.
Problem~8 found a decomposition that made everything else fall out.
And Problem~6---after eight hours of TryHarder in the sparsification
layer---found an elementary combinatorial proof within fifteen minutes
of a coaching intervention that forced layer enumeration.

In every case the git log for the successful phase is a record of
\emph{reframing}, not persistence.  The git log for Problem~6's
failed phase is a record of persistence within the wrong frame.

For future sprints---human or AI---the design implications are:

\begin{enumerate}
\item \textbf{Make success histories as visible as failure histories.}
  An agent stuck on a problem should be prompted to consult the
  strategy traces of problems that closed, not just its own history
  of failed attempts.  Rumination is not learning.  Analogy is.
\item \textbf{Coach, don't dispatch.}  The intervention that broke
  Problem~6's TryHarder loop was not ``close the gap in Section~5''
  but ``what kind of problem is this?''  Dispatching generates another
  cycle.  Coaching generates a layer switch.
\item \textbf{Ask pedagogical questions.}  ``How would you teach this
  to an undergraduate?'' forces identification of the elementary core.
  For Problem~6, the elementary core \emph{was} the proof.
\end{enumerate}

\section{Toward Real-Time Argumentation Structure}

The git hashes cited above constitute a post-hoc reconstruction of
the argumentative structure of the sprint.  Each pivotal commit
records a move: an obstruction identified, a layer switched, an
identity discovered, a closure achieved.  The connections between
moves---``this obstruction motivated that layer switch''---are
implicit in the temporal ordering but not represented explicitly.

This is a degenerate form of the Argument Interchange Format
(AIF)~\cite{pease2017}, in which argument moves are nodes and
inferential, conflict, and preference relations are typed edges.
The git log provides the nodes (commits) but not the edges
(argumentative relations).

The gap between post-hoc annotation and real-time capture is
precisely the gap between this chapter and a live AIF graph.
In a real-time system, each proof step, obstruction, and strategy
shift would be recorded as an AIF node at the moment it occurs,
with edges to its premises, targets, and alternatives.  The
``proof patterns'' analysis would then be a graph query, not
a retrospective essay.

Three infrastructure pieces converge on this:

\begin{enumerate}
\item \textbf{Arxana} (futon5) provides the typed-edge graph substrate.
\item \textbf{The peripheral model} (futon3c) provides scoped contexts
  in which moves are recorded as they happen.
\item \textbf{S-expression canonical form} provides the representation
  in which argument structure and mathematical content coexist
  without a separate annotation layer.
\end{enumerate}

With all three, the sprint's argumentative structure would be captured
as it unfolds---not reconstructed from git hashes months later.
The distance from the present chapter to that system is a tooling
gap, not a conceptual one.
