\chapter{Strategy Patterns Across Ten Problems}

The ten proofs in Part~II were not produced by a uniform method.
Some closed quickly; others required layer-switching, creative
reductions, or honest declarations of conditionality.
This chapter extracts the transferable strategy patterns---what
worked, what didn't, and what an agent stuck on one problem
could learn from the successes of another.

\section{Three Sprint Outcomes}

Every open problem in a sprint has one of three honest outcomes:

\begin{enumerate}
\item \textbf{Closed.} A complete proof (possibly with minor caveats).
  Problems 1--5, 7--10.
\item \textbf{Reduced.} A conditional result with clearly stated
  assumptions. Problem~6.
\item \textbf{Mapped.} The obstruction is characterized and adjacent
  problems are identified, but no proof is offered.
\end{enumerate}

All three are legitimate outcomes. Outcome~2 is not a defect of
outcome~1; it is a different kind of contribution.  The failure mode
is treating outcome~2 as something to repair rather than something
to state clearly.

\section{Success Pattern: Layer-Switching (Problem 7)}

Problem~7 (uniform lattice with 2-torsion) is the clearest example
of a successful strategy pivot.

\begin{description}
\item[Initial approach:] Reflection lattice in even dimension.
  The E2 obligation (Fowler's criterion) was discharged.
\item[Obstruction:] The surgery obligation (S) was blocked.
  Equivariant surgery requires a codimension-2 gap hypothesis;
  reflections give codimension-1 fixed sets.  Blocked.
\item[Characterization:] Instead of pushing harder on reflections,
  the obstruction was characterized structurally: a dimension-parity
  tension between E2 (needs even $n$) and S (better in odd $n$).
\item[Layer switch:] Replace reflections (codimension~1) with rotations
  (codimension~2).  Now $n$ is odd, E2 still works (fixed set has
  odd dimension, $\chi = 0$), and the codimension-2 gap hypothesis
  is satisfied.
\item[Closure:] The surgery obstruction vanishes (trivial normal
  bundle from the congruence condition).
\end{description}

\textbf{Transferable principle:} When blocked in one layer,
characterize the obstruction structurally before attempting to
overcome it.  The characterization may reveal that a different
layer avoids the obstruction entirely.

\section{Success Pattern: Creative Reduction (Problem 4)}

Problem~4 (root separation under finite free convolution)
progressed from numerical evidence to proof via a sequence
of reductions:

\begin{enumerate}
\item Centering reduction (translation invariance of $\Phi_n$).
\item For $n = 3$: discovery of the identity
  $\Phi_3 \cdot \mathrm{disc} = 18 \, a_2^2$ (exact, verified symbolically).
\item Recognition that the surplus expression has the form
  required by Titu's lemma (Engel form of Cauchy--Schwarz).
\end{enumerate}

Step~2 was the creative step---an identity discovered numerically
and verified symbolically.  The key was that the identity was
\emph{sought} because the reduction strategy demanded an algebraic
relationship between $\Phi_n$ and known invariants.  The strategy
shaped the search.

\textbf{Transferable principle:} Reductions create demand for
specific identities or lemmas.  The demand makes the search
targeted rather than exploratory.

\section{Success Pattern: Structural Decomposition (Problem 8)}

Problem~8 (Lagrangian smoothing of polyhedral surfaces) was stuck
until the symplectic direct sum decomposition was discovered:
the 4-face Lagrangian condition forces $\mathbb{R}^4 = V_1 \oplus V_2$.
This single structural insight unlocked everything---Maslov index
vanishing, vertex smoothing via product structure, and the
Hamiltonian isotopy property.

\textbf{Transferable principle:} Look for structural decompositions
that simplify the problem globally, not just local fixes for individual
obstacles.

\section{Failure Pattern: The TryHarder Loop (Problem 6)}

Problem~6 (epsilon-light subsets) generated six or more handoff
and dispatch documents across multiple sessions.  The pattern:

\begin{enumerate}
\item Identify the gap (Assumption~V: vertex-induced selection).
\item Attempt closure via a specific attack vector.
\item Fail.
\item Generate a new handoff document dispatching another attack.
\item Repeat from step~2.
\end{enumerate}

What was missing: honest layer-level calibration.  The problem has
multiple layers, each with a different reduction:

\begin{description}
\item[Spectral layer:] Bound $\|L^{+/2} L_S L^{+/2}\| \le \varepsilon$.
  \emph{Status: set up correctly.}
\item[Concentration layer:] Control martingale parameters $R_*$
  and $\|W_n\|$.  \emph{Status: framework correct, bounds need
  leverage analysis.}
\item[Combinatorial layer:] Vertex selection with leverage score
  constraints.  \emph{Status: star domination done.}
\item[Sparsification layer:] Adapt BSS from edges to vertices.
  \emph{Status: structural gap---BSS is fundamentally edge-based.}
\end{description}

The closure attempts mostly targeted the sparsification layer without
recognizing that the obstruction there might be structural (not a
gap to fill but a genuine mismatch between edge and vertex selection).
Meanwhile, three other layers had partial progress that was never
leveraged.

\textbf{Transferable principle:} When stuck, enumerate the layers
and assess status per layer.  Do not repeatedly attack the same
blocked layer.  Ask whether a different layer offers a path, or
whether the conditional result (stating the assumption explicitly)
is the honest outcome.

\section{Cross-Problem Learning}

An agent working on Problem~6 that could see Problem~7's history
would find: \emph{Problem~7 was blocked in one layer (codimension-1
surgery), characterized the obstruction, switched to a different
layer (codimension-2 surgery), and closed.}  This is directly
transferable advice.

More generally, the proof patterns across the ten problems suggest
a strategy checklist for open problems:

\begin{enumerate}
\item \textbf{Enumerate layers.}  What are the distinct mathematical
  frameworks in which this problem can be stated?
\item \textbf{Find the reduction in each layer.}  What does the problem
  reduce to from each perspective?
\item \textbf{Assess status per layer.}  Which reductions are complete,
  partial, or blocked?
\item \textbf{Characterize obstructions.}  For blocked layers, is the
  obstruction structural or technical?  Is there a known workaround?
\item \textbf{Look for analogues.}  Which other problems had a similar
  layer profile?  What strategy succeeded there?
\item \textbf{Decide the outcome.}  Is closure feasible from any layer?
  If not, state the conditional result and the open assumptions.
\end{enumerate}

This is case-based reasoning applied to proof strategy.  The ``cases''
are the other problems in the sprint (or, with a larger corpus, the
indexed literature).  The transfer is at the strategy level, not the
mathematical level---it is not that Problem~7's rotation trick applies
to Problem~6, but that Problem~7's \emph{layer-switching} strategy
might.

\section{Learning from Success, Not Just Failure}

A recurring theme: the sessions that closed problems did so by
finding the right \emph{frame}, not by working harder within
the wrong one.  Problem~7 switched from reflections to rotations.
Problem~4 found an identity that restructured the algebra.
Problem~8 found a decomposition that made everything else fall out.

The sessions that did not close (Problem~6) iterated within a
single frame.  The git log for Problem~6 is a record of persistence
within the sparsification layer.  The git log for Problem~7 is a
record of reframing.

For future sprints---human or AI---the design implication is:
\textbf{make success histories as visible as failure histories.}
An agent stuck on a problem should be prompted to consult the
strategy traces of problems that closed, not just its own history
of failed attempts.  Rumination is not learning.  Analogy is.
