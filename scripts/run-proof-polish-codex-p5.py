#!/usr/bin/env python3
"""Polish the Problem 5 proof via Codex CLI.

For each proof node in the wiring diagram, generates a verification prompt
and runs it through `codex exec`. Codex cross-references with math.SE/MO data
(when available), verifies mathematical claims, and identifies gaps.

Usage:
    # Generate prompts only (dry run)
    python3 scripts/run-proof-polish-codex-p5.py --dry-run

    # Run through Codex
    python3 scripts/run-proof-polish-codex-p5.py --limit 8

    # With custom math.SE search path
    python3 scripts/run-proof-polish-codex-p5.py --math-se-dir se-data/math-processed/
"""

from __future__ import annotations

import argparse
import json
import subprocess
import sys
import tempfile
from collections import Counter
from pathlib import Path


REPO_ROOT = Path(__file__).resolve().parent.parent
WIRING_JSON = REPO_ROOT / "data" / "first-proof" / "problem5-wiring.json"
SOLUTION_MD = REPO_ROOT / "data" / "first-proof" / "problem5-solution.md"
DEFAULT_OUTPUT = REPO_ROOT / "data" / "first-proof" / "problem5-codex-results.jsonl"
DEFAULT_PROMPTS = REPO_ROOT / "data" / "first-proof" / "problem5-codex-prompts.jsonl"
DEFAULT_MATH_SE_DIR = REPO_ROOT / "se-data" / "math-processed"


RESPONSE_SCHEMA = {
    "type": "object",
    "properties": {
        "node_id": {"type": "string"},
        "claim_verified": {
            "type": "string",
            "enum": ["verified", "plausible", "gap", "error"],
        },
        "verification_notes": {"type": "string"},
        "math_se_references": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "question_id": {"type": "integer"},
                    "title": {"type": "string"},
                    "relevance": {"type": "string"},
                    "site": {
                        "type": "string",
                        "enum": ["math.stackexchange.com", "mathoverflow.net", "other", "unknown"],
                    },
                },
                "required": ["question_id", "title", "relevance"],
                "additionalProperties": False,
            },
        },
        "suggested_improvement": {"type": "string"},
        "missing_assumptions": {
            "type": "array",
            "items": {"type": "string"},
        },
        "confidence": {
            "type": "string",
            "enum": ["high", "medium", "low"],
        },
    },
    "required": [
        "node_id",
        "claim_verified",
        "verification_notes",
        "math_se_references",
        "suggested_improvement",
        "missing_assumptions",
        "confidence",
    ],
    "additionalProperties": False,
}


# Verification focus for each proof step
NODE_VERIFICATION_FOCUS = {
    "p5-problem": (
        "Verify the problem is well-posed: (a) 'incomplete transfer system' has a "
        "precise meaning via Blumberg-Hill N_infinity operads — confirm the problem "
        "is asking for a slice filtration adapted to this data. (b) Check whether "
        "'O-slice filtration' is standard terminology or our coinage. (c) The "
        "problem asks to 'characterize O-slice connectivity' — does the literature "
        "already have a complete answer? Search MO for 'incomplete slice filtration' "
        "or 'N_infinity slice'."
    ),
    "p5-s1": (
        "Verify the baseline: Hill-Yarnall (arXiv:1703.10526) Definition 1.1 "
        "gives regular slice cells as G_+ wedge_H S^{k rho_H}. Confirm: "
        "(a) is rho_H the regular representation of H (not a reduced version)? "
        "(b) Theorem 2.5 states the geometric-fixed-point characterization — "
        "what are the exact connectivity bounds? (c) Does this require 'connective' "
        "as a hypothesis? (d) Is the localizing subcategory generated by these cells "
        "the same as the right-Bousfield localization used in HHR?"
    ),
    "p5-s2": (
        "Verify the Blumberg-Hill framework: (a) Definition 1.1 of arXiv:1309.1750 "
        "defines N_infinity operads. (b) Theorem 1.2 gives a fully faithful "
        "embedding of the homotopy category of N_infinity operads into indexing "
        "systems (equivalently, transfer systems). (c) Confirm that transfer "
        "systems control WHICH transfers/norms exist, not a modified representation. "
        "(d) Search MO for whether anyone has defined an 'O-regular representation' — "
        "if not, that confirms our correction was right."
    ),
    "p5-s3": (
        "This is the KEY DEFINITION. Verify: (a) defining tau_{>=n}^O by "
        "restricting generators to H in F_O (where F_O = {H : transfer e->H is "
        "in T_O}) is a well-defined localizing subcategory. (b) Is F_O the right "
        "family? Should it be 'H such that the norm N_e^H exists' instead of "
        "'transfer e->H exists'? Transfers and norms are different in the "
        "Blumberg-Hill framework. (c) Check: with fewer generators, tau_{>=n}^O "
        "is CONTAINED in the full tau_{>=n} (smaller subcategory, so MORE spectra "
        "are O-slice connective). Is this the right monotonicity? (d) Are there "
        "alternative definitions in the literature?"
    ),
    "p5-s4": (
        "Verify the characterization theorem: X in tau_{>=n}^O iff Phi^H X is "
        "(ceil(n/|H|)-1)-connected for all H in F_O. Key checks: "
        "(a) The forward direction (X in tau => connectivity) should follow from "
        "the cell structure: cells have Phi^H of the right connectivity. "
        "(b) The REVERSE direction (connectivity => X in tau) is harder: does "
        "testing against fewer generators (only H in F_O) suffice? In the full "
        "case, Hill-Yarnall uses all subgroups. With fewer subgroups, we have "
        "LESS detection, so the reverse direction should be EASIER (fewer conditions "
        "to satisfy). But is the argument that the definition and detection are "
        "matched (both use only F_O) rigorous? "
        "(c) Does 'connective' here mean underlying connective, or slice-connective?"
    ),
    "p5-s5": (
        "Verify the proof sketch's key computation: Phi^H(G_+ wedge_H S^{k rho_H}) "
        "~= S^k. Check: (a) This uses the geometric fixed point computation for "
        "induced spectra. The standard formula is Phi^K(G_+ wedge_H X) = "
        "bigvee_{KgH : g^{-1}Kg <= H} Phi^{g^{-1}Kg}(X). For K=H this should give "
        "Phi^H(S^{k rho_H}). (b) rho_H has dim |H| with Phi^H(S^{rho_H}) = S^1 "
        "(one trivial summand). So Phi^H(S^{k rho_H}) = S^k. Confirm this. "
        "(c) For K != H (K a different subgroup in F_O), what does "
        "Phi^K(G_+ wedge_H S^{k rho_H}) look like? This matters for cross-detection "
        "between different subgroups."
    ),
    "p5-s6": (
        "Verify the special cases: (a) Complete transfer system (F_O = all "
        "subgroups): should recover Hill-Yarnall Theorem A exactly. Does it? "
        "(b) Trivial transfer system (F_O = {e}): should give Postnikov. "
        "If F_O = {e}, the only condition is Phi^e X = X^e is "
        "(ceil(n/1)-1) = (n-1)-connected. That is indeed the Postnikov condition. "
        "Confirm. (c) For G = C_2 with the complete system: the criterion should "
        "give two conditions (H=e and H=C_2). Does it match HHR? "
        "(d) For G = C_{p^2} with T = {{e}, C_p}: we check H=e and H=C_p. "
        "Work out the explicit bounds."
    ),
}


def build_node_prompt(
    node: dict,
    edges: list[dict],
    solution_text: str,
    math_se_dir: Path | None = None,
) -> str:
    """Build a verification prompt for a single proof node."""
    node_id = node["id"]
    focus = NODE_VERIFICATION_FOCUS.get(node_id, "Verify the mathematical claim.")

    # Find edges involving this node
    incoming = [e for e in edges if e["target"] == node_id]
    outgoing = [e for e in edges if e["source"] == node_id]

    lines = [
        "You are a mathematical proof verifier with expertise in equivariant "
        "stable homotopy theory, slice filtrations, N_infinity operads, "
        "transfer systems, and geometric fixed points.",
        "",
        "## Task",
        "",
        "Verify one step of a proof that defines an O-slice filtration (adapted "
        "to an incomplete transfer system) and characterizes O-slice connectivity "
        "via geometric fixed points. Cross-reference with math.SE/MO discussions "
        "and primary sources (Hill-Yarnall arXiv:1703.10526, Blumberg-Hill "
        "arXiv:1309.1750, HHR) when possible.",
        "",
        "## Proof Step Under Review",
        "",
        f"**Node ID**: {node_id}",
        f"**Type**: {node['node_type']}",
        f"**Claim**: {node['body_text']}",
        "",
        "## Verification Focus",
        "",
        focus,
        "",
    ]

    if incoming:
        lines.append("## Incoming Edges (this step depends on)")
        for e in incoming:
            lines.append(f"  - {e['source']} -> {node_id} [{e['edge_type']}]: {e['evidence']}")
        lines.append("")

    if outgoing:
        lines.append("## Outgoing Edges (this step supports)")
        for e in outgoing:
            lines.append(f"  - {node_id} -> {e['target']} [{e['edge_type']}]: {e['evidence']}")
        lines.append("")

    lines.extend([
        "## Full Problem Context",
        "",
        "Problem 5 asks: for a finite group G with an incomplete transfer system "
        "T_O (from an N_infinity operad O), define a slice filtration adapted to O "
        "and characterize O-slice connectivity of connective G-spectra.",
        "",
        "The approach: use standard regular slice cells G_+ wedge_H S^{k rho_H}, "
        "but restrict subgroup indexing to H in F_O = {H : transfer e->H is in T_O}. "
        "The characterization is: X is O-slice >= n iff Phi^H X is "
        "(ceil(n/|H|)-1)-connected for all H in F_O.",
        "",
        "Key correction from earlier draft: there is no 'O-regular representation' "
        "rho_H^O. Transfer systems restrict which subgroups participate, not the "
        "representation used in slice cells.",
        "",
        "## Important Background",
        "",
        "- Hill-Yarnall (arXiv:1703.10526): regular slice generators and "
        "geometric-fixed-point characterization",
        "- Blumberg-Hill (arXiv:1309.1750): N_infinity operads, transfer systems, "
        "indexing systems",
        "- HHR: equivariant stable homotopy theory and Kervaire invariant problem "
        "(original slice framework)",
        "",
        "## Instructions",
        "",
        "1. Verify the mathematical claim in this proof step.",
        "2. Search math.SE/MO for relevant discussions (slice filtration, "
        "N_infinity operad, transfer system, geometric fixed points, equivariant "
        "stable homotopy, regular slice, incomplete transfers).",
        "3. Identify any gaps, unstated assumptions, or potential errors.",
        "4. Suggest improvements if the claim could be tightened or clarified.",
        "5. For each reference, include `site` when known "
        "(e.g., `mathoverflow.net` or `math.stackexchange.com`).",
        "6. Reply as a single JSON object matching the required schema.",
    ])
    if math_se_dir:
        lines.extend([
            "",
            "## Local Corpus Hint",
            "",
            f"Use local processed data if available under: {math_se_dir}",
        ])

    return "\n".join(lines)


def build_synthesis_prompt(
    solution_text: str,
    wiring: dict,
    math_se_dir: Path | None = None,
) -> str:
    """Build a synthesis prompt that reviews the entire proof."""
    stats = wiring.get("stats", {})
    return "\n".join([
        "You are a mathematical proof verifier reviewing a complete proof.",
        "",
        "## Task",
        "",
        "Review this proof that defines an O-slice filtration for incomplete "
        "transfer systems and characterizes O-slice connectivity via geometric "
        "fixed points. Assess completeness, correctness, and suggest improvements.",
        "",
        "## Proof",
        "",
        solution_text,
        "",
        "## Wiring Diagram Summary",
        "",
        f"Nodes: {stats.get('n_nodes', '?')}, Edges: {stats.get('n_edges', '?')}",
        f"Edge types: {json.dumps(stats.get('edge_types', {}))}",
        "",
        "## Instructions",
        "",
        "1. Is the proof complete? Does the characterization theorem follow from "
        "the stated steps?",
        "2. KEY QUESTION: Is the definition of F_O correct? Should it use "
        "'transfer e->H exists' or 'norm N_e^H exists' or something else? "
        "In Blumberg-Hill, transfers and norms are related but different.",
        "3. The proof sketch (Section 5) claims Phi^H(G_+ wedge_H S^{k rho_H}) "
        "~= S^k. Verify this computation carefully. What happens for K != H?",
        "4. The reverse direction of the characterization (connectivity implies "
        "membership in the localizing subcategory) needs scrutiny. In the full "
        "case Hill-Yarnall uses all subgroups. Does restricting to F_O still work?",
        "5. Is this result already known? Search for 'incomplete slice filtration' "
        "or 'N_infinity slice' on MO/math.SE.",
        "6. The confidence is 'Medium' — what would raise it to 'Medium-high'?",
        "7. For each reference, include `site` when known "
        "(e.g., `mathoverflow.net` or `math.stackexchange.com`).",
        "8. Reply as a single JSON object matching the required schema. "
        "Use node_id='p5-synthesis' for the synthesis.",
    ])
    if math_se_dir:
        lines.extend([
            "",
            "## Local Corpus Hint",
            "",
            f"Use local processed data if available under: {math_se_dir}",
        ])
    return "\n".join(lines)


def run_codex_once(
    codex_bin: str,
    model: str,
    cwd: Path,
    schema_path: Path,
    prompt_text: str,
) -> tuple[int, str, str]:
    """Run a single prompt through codex exec."""
    with tempfile.NamedTemporaryFile("w+", suffix=".txt", delete=False) as out_f:
        out_path = Path(out_f.name)

    instruction = (
        "You must answer exactly as one JSON object matching the required schema. "
        "Do not wrap JSON in markdown fences. Do not add extra commentary.\n\n"
        + prompt_text
    )
    cmd = [
        codex_bin,
        "exec",
        "--cd", str(cwd),
        "--sandbox", "workspace-write",
        "--model", model,
        "--output-schema", str(schema_path),
        "--output-last-message", str(out_path),
        "-",
    ]
    proc = subprocess.run(cmd, input=instruction, text=True, capture_output=True)
    try:
        response_text = out_path.read_text(encoding="utf-8").strip()
    except FileNotFoundError:
        response_text = ""
    out_path.unlink(missing_ok=True)
    return proc.returncode, response_text, proc.stderr.strip()


def main() -> int:
    ap = argparse.ArgumentParser(description=__doc__)
    ap.add_argument("--wiring", type=Path, default=WIRING_JSON)
    ap.add_argument("--solution", type=Path, default=SOLUTION_MD)
    ap.add_argument("--output", type=Path, default=DEFAULT_OUTPUT)
    ap.add_argument("--prompts-out", type=Path, default=DEFAULT_PROMPTS)
    ap.add_argument("--limit", type=int, default=None,
                    help="Max prompts to process (default: all generated prompts)")
    ap.add_argument("--model", default="gpt-5.3-codex")
    ap.add_argument("--codex-bin", default="codex")
    ap.add_argument("--dry-run", action="store_true",
                    help="Generate prompts only, don't call Codex")
    ap.add_argument("--math-se-dir", type=Path, default=DEFAULT_MATH_SE_DIR,
                    help="Local processed StackExchange data directory (hinted to Codex prompts)")
    ap.add_argument("--repo-root", type=Path, default=REPO_ROOT)
    args = ap.parse_args()

    # Load wiring diagram
    if not args.wiring.exists():
        print(f"Wiring diagram not found: {args.wiring}", file=sys.stderr)
        print("Run: python3 scripts/proof5-wiring-diagram.py", file=sys.stderr)
        return 2
    wiring = json.loads(args.wiring.read_text())

    # Load solution
    solution_text = ""
    if args.solution.exists():
        solution_text = args.solution.read_text()

    nodes = wiring["nodes"]
    edges = wiring["edges"]

    # Build prompts for each node
    prompts = []
    for node in nodes:
        prompt_text = build_node_prompt(
            node,
            edges,
            solution_text,
            math_se_dir=args.math_se_dir,
        )
        prompts.append({
            "node_id": node["id"],
            "node_type": node["node_type"],
            "prompt": prompt_text,
        })

    # Add synthesis prompt
    prompts.append({
        "node_id": "p5-synthesis",
        "node_type": "synthesis",
        "prompt": build_synthesis_prompt(solution_text, wiring, math_se_dir=args.math_se_dir),
    })
    run_limit = len(prompts) if args.limit is None else min(args.limit, len(prompts))

    # Write prompts
    args.prompts_out.parent.mkdir(parents=True, exist_ok=True)
    with open(args.prompts_out, "w") as f:
        for rec in prompts:
            f.write(json.dumps(rec, ensure_ascii=False) + "\n")
    print(f"Wrote {len(prompts)} prompts to {args.prompts_out}")

    if args.dry_run:
        print("Dry run -- not calling Codex.")
        print(f"\nPrompt summary ({len(prompts)} prompts, run_limit={run_limit}):")
        for p in prompts:
            lines = p["prompt"].count("\n") + 1
            print(f"  {p['node_id']:20s} [{p['node_type']:10s}] ~{lines} lines")
        return 0

    # Run through Codex
    args.output.parent.mkdir(parents=True, exist_ok=True)
    verified = Counter()
    processed = 0

    with tempfile.NamedTemporaryFile("w", suffix=".json", delete=False) as sf:
        json.dump(RESPONSE_SCHEMA, sf, ensure_ascii=True, indent=2)
        schema_path = Path(sf.name)

    try:
        with open(args.output, "w") as fout:
            for rec in prompts[:run_limit]:
                rc, raw_response, stderr_text = run_codex_once(
                    codex_bin=args.codex_bin,
                    model=args.model,
                    cwd=args.repo_root,
                    schema_path=schema_path,
                    prompt_text=rec["prompt"],
                )

                out = {"node_id": rec["node_id"]}
                try:
                    parsed = json.loads(raw_response)
                    if isinstance(parsed, dict):
                        out.update(parsed)
                        v = parsed.get("claim_verified", "")
                        if v in ("verified", "plausible", "gap", "error"):
                            verified[v] += 1
                    else:
                        out["parse_error"] = True
                        out["raw"] = raw_response
                except Exception:
                    out["parse_error"] = True
                    parts = []
                    if raw_response:
                        parts.append(raw_response)
                    if rc != 0:
                        parts.append(f"[codex_exit_code={rc}]")
                    if stderr_text:
                        parts.append(f"[stderr]\n{stderr_text}")
                    out["raw"] = "\n".join(parts).strip()

                fout.write(json.dumps(out, ensure_ascii=False) + "\n")
                processed += 1
                status = out.get("claim_verified", "parse_error" if out.get("parse_error") else "?")
                print(f"[{processed:02d}/{run_limit}] {rec['node_id']:20s} -> {status}")
                sys.stdout.flush()
    finally:
        schema_path.unlink(missing_ok=True)

    print("\n---SUMMARY---")
    print(f"processed={processed}")
    print(f"verified={verified['verified']}, plausible={verified['plausible']}, "
          f"gap={verified['gap']}, error={verified['error']}")
    print(f"output={args.output}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
